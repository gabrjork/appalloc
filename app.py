import streamlit as st
import pandas as pd
import numpy as np
import requests
import matplotlib.pyplot as plt
from bcb import sgs
from bcb import Expectativas
import pyettj
from datetime import datetime, timedelta
from scipy import interpolate
from scipy.optimize import minimize
import io
import base64

# --- 1. CONFIGURA√á√ÉO DA P√ÅGINA E ESTILIZA√á√ÉO ---
st.set_page_config(page_title="Ghia MFO - Asset Allocation", layout="wide")

st.markdown("""
<style>
    [data-testid="stSidebar"] { min-width: 200px; max-width: 250px; }
    [data-testid="stSidebar"] .block-container { padding-top: 2rem; padding-bottom: 1rem; }
    
    /* Radio buttons na p√°gina - item selecionado em branco */
    div[role="radiogroup"] > label > div:first-of-type { display: none; }
    div[role="radiogroup"] label { padding-left: 0px !important; }
    div[role="radiogroup"] p { font-size: 15px; font-weight: 500; color: #808495; }
    div[role="radiogroup"] label[data-baseweb="radio"] input:checked ~ div p { color: #FFFFFF !important; font-weight: 700; }
    
    /* Selectbox (perfil) - texto selecionado em branco */
    div[data-baseweb="select"] span { color: #FFFFFF !important; font-weight: 600; }
    
    /* Menu lateral - p√°ginas */
    [data-testid="stSidebar"] button[kind="secondary"] p { color: #808495 !important; }
    [data-testid="stSidebar"] button[kind="primary"] p { color: #FFFFFF !important; font-weight: 700 !important; }
    
    header {visibility: hidden;}
    .stAlert { padding: 0.5rem 1rem; }
</style>
""", unsafe_allow_html=True)

# --- 2. FUN√á√ïES DE DADOS P√öBLICOS ---

@st.cache_data
def get_historico_real():
    try:
        df = sgs.get({'IPCA': 433, 'CDI': 4391}, start='2005-01-01')
        df = df / 100
        df['Juro_Real'] = ((1 + df['CDI']) / (1 + df['IPCA'])) - 1
        df['Juro_Real_12m'] = df['Juro_Real'].rolling(12).apply(lambda x: np.prod(1 + x) - 1)
        df = df.dropna()
        if len(df) >= 60:
            media_5y = df['Juro_Real_12m'].iloc[-60:].mean()
        else:
            media_5y = df['Juro_Real_12m'].mean()
        return df, media_5y
    except Exception:
        return pd.DataFrame(), 0.05

@st.cache_data
def get_expectativa_inflacao_12m():
    try:
        em = Expectativas()
        ep = em.get_endpoint('ExpectativasMercadoInflacao12Meses')
        end_date = datetime.now().strftime('%Y-%m-%d')
        start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
        df_focus = ep.query().filter(ep.Indicador == 'IPCA').filter(ep.baseCalculo == 0).filter(ep.Data >= start_date).collect()
        if not df_focus.empty:
            df_focus = df_focus.sort_values('Data')
            return df_focus.iloc[-1]['Mediana'] / 100
        return 0.04
    except Exception:
        return 0.04

@st.cache_data
def get_ettj_1ano():
    for i in range(0, 5):
        data_busca = datetime.now() - timedelta(days=i)
        data_str = data_busca.strftime("%d/%m/%Y")
        try:
            curva = pyettj.get_ettj(data_str)
            if not curva.empty and 'Dias Corridos' in curva.columns:
                curva = curva.sort_values('Dias Corridos')
                f_interp = interpolate.interp1d(curva['Dias Corridos'], curva['DI x pr√© 252'], kind='linear', fill_value="extrapolate")
                return float(f_interp(365)) / 100, data_str
        except Exception:
            continue
    return 0.12, "Erro/Fallback"

@st.cache_data
def get_taxa_pre_vertice_504():
    """Busca taxa pr√© do v√©rtice 504 dias da ETTJ"""
    for i in range(0, 10):  # Aumenta busca para 10 dias (pega semana anterior)
        data_busca = datetime.now() - timedelta(days=i)
        # Pula finais de semana
        if data_busca.weekday() >= 5:  # 5=s√°bado, 6=domingo
            continue
        
        data_str = data_busca.strftime("%d/%m/%Y")
        try:
            # USA get_ettj_anbima() para obter v√©rtices padronizados da ANBIMA
            # Retorna tupla: (params_svensson, vertices_anbima, prefixados, titulos)
            resultado = pyettj.get_ettj_anbima(data_str)
            curva = resultado[1]  # Pega o DataFrame de v√©rtices (√≠ndice 1)
            
            # Colunas: ['Vertice', 'IPCA', 'Prefixados', 'Infla√ß√£o Impl√≠cita']
            if not curva.empty and 'Vertice' in curva.columns and 'Prefixados' in curva.columns:
                # Converte colunas para num√©rico (trata formata√ß√£o brasileira)
                # Remove pontos de milhar ANTES de converter (ex: "1.008" ‚Üí "1008")
                curva['Vertice'] = curva['Vertice'].apply(lambda x: str(x).replace('.', ''))
                curva['Vertice'] = pd.to_numeric(curva['Vertice'], errors='coerce')
                # Converte taxas: troca v√≠rgula por ponto (ex: "13,0208" ‚Üí 13.0208)
                curva['Prefixados'] = curva['Prefixados'].apply(
                    lambda x: float(str(x).replace(',', '.')) if pd.notna(x) and str(x).strip() != '' else None
                )
                # Remove linhas com valores vazios
                curva = curva.dropna(subset=['Vertice', 'Prefixados'])
                curva = curva.sort_values('Vertice')
                
                # Com get_ettj_anbima(), o v√©rtice 504 deve existir exatamente
                if 504 in curva['Vertice'].values:
                    taxa = curva[curva['Vertice'] == 504]['Prefixados'].iloc[0]
                    valor_interpolado = False
                else:
                    # Fallback: interpola se n√£o existir (n√£o deveria acontecer)
                    f_interp = interpolate.interp1d(curva['Vertice'], curva['Prefixados'], 
                                                   kind='linear', fill_value="extrapolate")
                    taxa = float(f_interp(504))
                    valor_interpolado = True
                
                # Debug: salva info da curva
                vertice_504_row = curva[curva['Vertice'] == 504] if 504 in curva['Vertice'].values else None
                st.session_state['debug_ettj_pre'] = {
                    'data': data_str,
                    'colunas': curva.columns.tolist(),
                    'sample_completo': curva.to_dict('records'),
                    'vertice_504_existe': (504 in curva['Vertice'].values),
                    'taxa_retornada': taxa,
                    'foi_interpolado': valor_interpolado,
                    'vertice_504_row': vertice_504_row.to_dict('records') if vertice_504_row is not None and not vertice_504_row.empty else None,
                    'min_dias': curva['Vertice'].min(),
                    'max_dias': curva['Vertice'].max()
                }
                
                return taxa / 100, data_str  # J√° vem em %
        except Exception as e:
            st.session_state['debug_ettj_pre_error'] = str(e)
            continue
    return 0.12, "Erro/Fallback"

@st.cache_data
def get_taxa_real_vertice_1638():
    """Busca taxa real (DI x IPCA) do v√©rtice 1638 dias da ETTJ"""
    for i in range(0, 10):  # Aumenta busca para 10 dias (pega semana anterior)
        data_busca = datetime.now() - timedelta(days=i)
        # Pula finais de semana
        if data_busca.weekday() >= 5:  # 5=s√°bado, 6=domingo
            continue
        
        data_str = data_busca.strftime("%d/%m/%Y")
        try:
            # USA get_ettj_anbima() para obter v√©rtices padronizados da ANBIMA
            # Retorna tupla: (params_svensson, vertices_anbima, prefixados, titulos)
            resultado = pyettj.get_ettj_anbima(data_str)
            curva = resultado[1]  # Pega o DataFrame de v√©rtices (√≠ndice 1)
            
            # Colunas: ['Vertice', 'IPCA', 'Prefixados', 'Infla√ß√£o Impl√≠cita']
            if not curva.empty and 'Vertice' in curva.columns and 'IPCA' in curva.columns:
                # Converte colunas para num√©rico (trata formata√ß√£o brasileira)
                # Remove pontos de milhar ANTES de converter (ex: "1.638" ‚Üí "1638")
                curva['Vertice'] = curva['Vertice'].apply(lambda x: str(x).replace('.', ''))
                curva['Vertice'] = pd.to_numeric(curva['Vertice'], errors='coerce')
                # Converte taxas: troca v√≠rgula por ponto (ex: "7,4832" ‚Üí 7.4832)
                curva['IPCA'] = curva['IPCA'].apply(
                    lambda x: float(str(x).replace(',', '.')) if pd.notna(x) and str(x).strip() != '' else None
                )
                # Remove linhas com valores vazios
                curva = curva.dropna(subset=['Vertice', 'IPCA'])
                curva = curva.sort_values('Vertice')
                
                # Com get_ettj_anbima(), o v√©rtice 1638 deve existir exatamente
                if 1638 in curva['Vertice'].values:
                    taxa = curva[curva['Vertice'] == 1638]['IPCA'].iloc[0]
                    valor_interpolado = False
                else:
                    # Fallback: interpola se n√£o existir (n√£o deveria acontecer)
                    f_interp = interpolate.interp1d(curva['Vertice'], curva['IPCA'], 
                                                   kind='linear', fill_value="extrapolate")
                    taxa = float(f_interp(1638))
                    valor_interpolado = True
                
                # Debug: salva info da curva
                vertice_1638_row = curva[curva['Vertice'] == 1638] if 1638 in curva['Vertice'].values else None
                st.session_state['debug_ettj_real'] = {
                    'data': data_str,
                    'colunas': curva.columns.tolist(),
                    'sample_completo': curva.to_dict('records'),
                    'vertice_1638_existe': (1638 in curva['Vertice'].values),
                    'taxa_retornada': taxa,
                    'foi_interpolado': valor_interpolado,
                    'vertice_1638_row': vertice_1638_row.to_dict('records') if vertice_1638_row is not None and not vertice_1638_row.empty else None,
                    'min_dias': curva['Vertice'].min(),
                    'max_dias': curva['Vertice'].max()
                }
                
                return taxa / 100, data_str  # J√° vem em %
        except Exception as e:
            st.session_state['debug_ettj_real_error'] = str(e)
            continue
    return 0.064, "Erro/Fallback"

@st.cache_data
def get_taxa_real_ex_ante_252():
    """Busca taxa real ex-ante (DI x IPCA) do v√©rtice 252 dias √∫teis (1 ano) da ETTJ ANBIMA"""
    for i in range(0, 10):
        data_busca = datetime.now() - timedelta(days=i)
        # Pula finais de semana
        if data_busca.weekday() >= 5:
            continue
        
        data_str = data_busca.strftime("%d/%m/%Y")
        try:
            resultado = pyettj.get_ettj_anbima(data_str)
            curva = resultado[1]  # DataFrame de v√©rtices
            
            if not curva.empty and 'Vertice' in curva.columns and 'IPCA' in curva.columns:
                # Converte colunas para num√©rico
                curva['Vertice'] = curva['Vertice'].apply(lambda x: str(x).replace('.', ''))
                curva['Vertice'] = pd.to_numeric(curva['Vertice'], errors='coerce')
                curva['IPCA'] = curva['IPCA'].apply(
                    lambda x: float(str(x).replace(',', '.')) if pd.notna(x) and str(x).strip() != '' else None
                )
                curva = curva.dropna(subset=['Vertice', 'IPCA'])
                curva = curva.sort_values('Vertice')
                
                # Busca v√©rtice 252 dias √∫teis (1 ano)
                if 252 in curva['Vertice'].values:
                    taxa = curva[curva['Vertice'] == 252]['IPCA'].iloc[0]
                    valor_interpolado = False
                else:
                    # Interpola se n√£o existir exato
                    f_interp = interpolate.interp1d(curva['Vertice'], curva['IPCA'], 
                                                   kind='linear', fill_value="extrapolate")
                    taxa = float(f_interp(252))
                    valor_interpolado = True
                
                # Debug
                st.session_state['debug_ettj_real_exante'] = {
                    'data': data_str,
                    'vertice_252_existe': (252 in curva['Vertice'].values),
                    'taxa_retornada': taxa,
                    'foi_interpolado': valor_interpolado
                }
                
                return taxa / 100, data_str
        except Exception as e:
            st.session_state['debug_ettj_real_exante_error'] = str(e)
            continue
    return 0.05, "Erro/Fallback"

# --- 3. FUN√á√ïES DE OTIMIZA√á√ÉO ---

def black_litterman(S, market_caps, tau, P, Q, omega):
    """
    Implementa√ß√£o do modelo Black-Litterman
    
    Args:
        S: Matriz de covari√¢ncia (numpy array)
        market_caps: Pesos de equil√≠brio de mercado (numpy array)
        tau: Par√¢metro de incerteza (scalar, tipicamente entre 0.01 e 0.05)
        P: Matriz de views (numpy array) - cada linha √© uma view
        Q: Vetor de retornos esperados das views (numpy array)
        omega: Matriz de incerteza das views (numpy array, diagonal)
    
    Returns:
        mu_bl: Retornos esperados ajustados pelo Black-Litterman
    """
    # Calcula o vetor de retornos impl√≠citos do mercado (Pi)
    # Assume risk aversion = 2.5 (t√≠pico)
    risk_aversion = 2.5
    pi = risk_aversion * S @ market_caps
    
    # F√≥rmula do Black-Litterman
    # mu_BL = [(tau*S)^-1 + P'*Omega^-1*P]^-1 * [(tau*S)^-1*Pi + P'*Omega^-1*Q]
    tau_S = tau * S
    tau_S_inv = np.linalg.inv(tau_S)
    
    omega_inv = np.linalg.inv(omega)
    
    # Termo da esquerda: [(tau*S)^-1 + P'*Omega^-1*P]^-1
    left_term = np.linalg.inv(tau_S_inv + P.T @ omega_inv @ P)
    
    # Termo da direita: [(tau*S)^-1*Pi + P'*Omega^-1*Q]
    right_term = tau_S_inv @ pi + P.T @ omega_inv @ Q
    
    # Retorno esperado ajustado
    mu_bl = left_term @ right_term
    
    return mu_bl

def risk_parity_optimization(S, vol_target=None):
    """
    Otimiza√ß√£o Risk Parity - equaliza contribui√ß√£o de risco
    
    Args:
        S: Matriz de covari√¢ncia (numpy array)
        vol_target: Volatilidade alvo anual (opcional). Se None, retorna pesos n√£o alavancados
    
    Returns:
        weights: Pesos otimizados (numpy array)
    """
    num_assets = S.shape[0]
    
    # Fun√ß√£o objetivo: minimizar a diferen√ßa entre contribui√ß√µes de risco
    def risk_contribution_diff(w):
        """Calcula diferen√ßa entre contribui√ß√µes de risco (queremos minimizar)"""
        portfolio_var = w.T @ S @ w
        portfolio_vol = np.sqrt(portfolio_var)
        
        # Contribui√ß√£o marginal de risco
        marginal_contrib = S @ w
        
        # Contribui√ß√£o de risco de cada ativo
        risk_contrib = w * marginal_contrib / portfolio_vol if portfolio_vol > 0 else w * 0
        
        # Contribui√ß√£o de risco alvo (igual para todos)
        target_contrib = portfolio_var / num_assets
        
        # Soma dos quadrados das diferen√ßas
        return np.sum((risk_contrib - target_contrib)**2)
    
    # Chute inicial: pesos iguais
    init_guess = num_assets * [1. / num_assets,]
    
    # Restri√ß√µes: soma = 1, todos positivos
    constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}
    bounds = tuple((0, 1) for _ in range(num_assets))
    
    # Otimiza√ß√£o
    result = minimize(
        risk_contribution_diff,
        init_guess,
        method='SLSQP',
        bounds=bounds,
        constraints=constraints,
        options={'maxiter': 1000, 'ftol': 1e-9}
    )
    
    if result.success:
        weights = result.x
        
        # Se houver target de volatilidade, aplica alavancagem
        if vol_target is not None:
            current_vol = np.sqrt(weights.T @ S @ weights)
            leverage = vol_target / current_vol if current_vol > 0 else 1
            weights = weights * leverage
        
        return weights
    else:
        # Fallback: pesos iguais
        return np.array(init_guess)

# --- 4. INTEGRA√á√ÉO COMDINHEIRO (HARDCODED PAYLOAD) ---
def fetch_comdinheiro_data(user, password):
    """
    Usa a string exata fornecida pelo suporte da Comdinheiro, apenas injetando o login.
    Mudei format=json3 para json2 para facilitar o processamento tabular.
    """
    url = "https://api.comdinheiro.com.br/v1/ep1/import-data"
    
    # Payload com JSON2 e max_list_size=10000
    # REMOVIDO cabecalho_excel=modo1 que pode estar causando retorno apenas de metadados
    payload = (
        f"username={user}&password={password}&"
        "URL=HistoricoCotacao002.php%3F%26x%3Dcdi%2Bibov%2Bifix%2Banbima_imab%2Banbima_irfm%2Banbima_idadi%2Banbima_ihfa%2Banbima_imab5%25BE%26data_ini%3D04012013%26data_fim%3D05122025%26pagina%3D1%26d%3DMOEDA_ORIGINAL%26g%3D1%26m%3D0%26info_desejada%3Dretorno%26retorno%3Ddiscreto%26tipo_data%3Ddu_br%26tipo_ajuste%3Dtodosajustes%26num_casas%3D2%26enviar_email%3D0%26ordem_legenda%3D1%26classes_ativos%3Dfklk448oj5v5r%26ordem_data%3D0%26rent_acum%3Drent_acum%26minY%3D%26maxY%3D%26deltaY%3D%26preco_nd_ant%3D0%26base_num_indice%3D100%26flag_num_indice%3D0%26eixo_x%3DData%26startX%3D0%26max_list_size%3D10000%26line_width%3D2%26titulo_grafico%3D%26legenda_eixoy%3D%26tipo_grafico%3Dline%26script%3D%26tooltip%3Dunica&format=json2"
    )
    
    headers = {'Content-Type': 'application/x-www-form-urlencoded'}
    
    try:
        response = requests.post(url, data=payload, headers=headers, timeout=60)
        
        if response.status_code == 200:
            data = response.json()
            
            if isinstance(data, dict) and 'erro' in data:
                return None, f"Erro API: {data['erro']}"
            
# Parser JSON2
            if 'resposta' in data:
                # Verifica se h√° dados em tab-p1 ao inv√©s de tab-p0
                rows_p0 = data['resposta'].get('tab-p0', {}).get('linha', []) if 'tab-p0' in data['resposta'] else []
                rows_p1 = data['resposta'].get('tab-p1', {}).get('linha', []) if 'tab-p1' in data['resposta'] else []
                
                # DEBUG COMPLETO DA RESPOSTA API
                st.session_state['api_full_response'] = {
                    'total_rows_p0': len(rows_p0),
                    'total_rows_p1': len(rows_p1),
                    'raw_json_keys': list(data.keys()),
                    'resposta_keys': list(data['resposta'].keys()) if 'resposta' in data else [],
                    'rows_p0': rows_p0[:10] if len(rows_p0) > 10 else rows_p0,
                    'rows_p1': rows_p1[:10] if len(rows_p1) > 10 else rows_p1,
                    'all_rows_p0': rows_p0,
                    'all_rows_p1': rows_p1
                }
                
                # Tenta usar tab-p1 se tab-p0 s√≥ tiver metadados
                if len(rows_p1) > len(rows_p0):
                    rows = rows_p1
                else:
                    rows = rows_p0
                
                if not rows:
                    return None, f"Nenhuma linha em tab-p0 ou tab-p1. Keys: {list(data.keys())}"
                df = pd.DataFrame(rows)
                
                # DEBUG: Salvar dados brutos em session_state para visualiza√ß√£o
                st.session_state['api_raw_data'] = {
                    'df_original': df.copy(),
                    'shape': df.shape,
                    'columns': df.columns.tolist(),
                    'first_rows': df.head(10).to_dict('records'),
                    'all_rows': df.to_dict('records'),  # TODAS as linhas
                    'dtypes': df.dtypes.to_dict()
                }
                
                # Verifica qual coluna de data existe (pode ser 'descricao' ou 'data')
                if 'descricao' in df.columns:
                    # TAB-P0: tem 'descricao' mas s√£o s√≥ metadados
                    # PULA AS PRIMEIRAS 3 LINHAS QUE S√ÉO METADADOS
                    df = df.iloc[3:].copy()
                    if len(df) == 0:
                        return None, "TAB-P0 s√≥ tem metadados, nenhum dado real."
                    df = df.rename(columns={'descricao': 'data'})
                elif 'data' in df.columns:
                    # TAB-P1: j√° vem com 'data' e s√£o dados reais (sem metadados)
                    pass
                else:
                    return None, f"Coluna de data n√£o encontrada. Colunas: {list(df.columns)}"
                
                # Tratamento de Data
                df['data'] = pd.to_datetime(df['data'], format="%d/%m/%Y", errors='coerce')
                df = df.dropna(subset=['data'])  # Remove linhas sem data v√°lida
                df = df.set_index('data')
                
                # Mapeamento das colunas que v√™m da API para os nomes do GHIA
                mapa = {
                    "cdi": "CDI (Caixa)",
                    "anbima_idadi": "IDA-DI (Cr√©dito)",
                    "anbima_imab": "IMA-B (Infla√ß√£o)",
                    "anbima_imab5+": "IMA-B 5+ (Il√≠quidos)",
                    "anbima_irfm": "IRF-M (Pr√©-fixado)",
                    "anbima_ihfa": "IHFA (Multimercado)",
                    "ibov": "IBOV (A√ß√µes BR)",
                    "ifix": "IFIX (FIIs)"
                }
                
                # Converte valores para num√©rico (j√° v√™m em formato decimal, N√ÉO dividir por 100!)
                for col in df.columns:
                    col_lower = col.lower()
                    if col_lower in mapa.keys():
                        # Converter n√∫meros (PT-BR: v√≠rgula para ponto)
                        # Remove "BRL" e outros textos que possam estar misturados
                        df[col] = df[col].astype(str).str.replace(',', '.').str.replace('BRL', '').str.strip()
                        df[col] = pd.to_numeric(df[col], errors='coerce')
                        # A API j√° retorna em formato DECIMAL (0.0006 = 0.06% retorno)
                        # N√ÉO dividir por 100 novamente!
                
                # Renomeia colunas que existirem (case-insensitive)
                cols_to_rename = {}
                for col in df.columns:
                    col_lower = col.lower()
                    if col_lower in mapa:
                        cols_to_rename[col] = mapa[col_lower]
                
                df = df.rename(columns=cols_to_rename)
                
                # Mant√©m apenas as colunas mapeadas
                cols_finais = [v for v in mapa.values() if v in df.columns]
                if not cols_finais:
                    return None, f"Nenhuma coluna de ativo reconhecida ap√≥s mapeamento. Colunas processadas: {df.columns.tolist()}"
                
                df = df[cols_finais]
                
                # Remove dias sem nenhum dado v√°lido (todas colunas NaN)
                df = df.dropna(how='all')
                
                # Para covari√¢ncia, melhor dropar NaNs do que preencher com 0
                # 0 representa retorno zero, n√£o aus√™ncia de dado
                df = df.dropna()
                
                if len(df) == 0:
                    return None, "DataFrame vazio ap√≥s limpeza. Verifique os dados da API."
                
                return df, f"Sucesso - {len(df)} dias de dados"
            else:
                return None, "Formato JSON inesperado."
        else:
            return None, f"Status HTTP: {response.status_code}"
            
    except Exception as e:
        return None, str(e)

# --- 4. EXECU√á√ÉO GLOBAL ---
with st.spinner('Sincronizando dados macroecon√¥micos...'):
    df_hist, media_juro_real_5y = get_historico_real()
    taxa_di_1y, data_ettj = get_ettj_1ano()
    expectativa_ipca = get_expectativa_inflacao_12m()
    
    # Busca taxa real ex-ante diretamente da ETTJ IPCA 252 dias
    taxa_real_ex_ante, data_real_exante = get_taxa_real_ex_ante_252()
    
    # Busca taxas dos v√©rtices espec√≠ficos da ETTJ
    taxa_pre_504, data_pre_504 = get_taxa_pre_vertice_504()
    taxa_real_1638, data_real_1638 = get_taxa_real_vertice_1638()

    if 'taxa_di_1y' not in st.session_state: st.session_state['taxa_di_1y'] = taxa_di_1y
    if 'data_ettj' not in st.session_state: st.session_state['data_ettj'] = data_ettj
    if 'taxa_real_ex_ante' not in st.session_state: st.session_state['taxa_real_ex_ante'] = taxa_real_ex_ante
    if 'data_real_exante' not in st.session_state: st.session_state['data_real_exante'] = data_real_exante
    if 'taxa_pre_504' not in st.session_state: st.session_state['taxa_pre_504'] = taxa_pre_504
    if 'data_pre_504' not in st.session_state: st.session_state['data_pre_504'] = data_pre_504
    if 'taxa_real_1638' not in st.session_state: st.session_state['taxa_real_1638'] = taxa_real_1638
    if 'data_real_1638' not in st.session_state: st.session_state['data_real_1638'] = data_real_1638

# --- 5. NAVEGA√á√ÉO ---
st.sidebar.markdown("### Navega√ß√£o")
pagina = st.sidebar.radio("Ir para:", ["Benchmark", "Cen√°rios Macro", "Otimiza√ß√£o"], label_visibility="collapsed")
st.sidebar.markdown("---")
with st.sidebar.container():
    st.markdown(f"""
    <div style="background-color: #262730; padding: 10px; border-radius: 5px; font-size: 12px; color: #DDD;">
        <strong style="color: #189CD8">Dados de Mercado</strong><br>
        Base Curva: {data_ettj}<br>
        DI Futuro (1Y): {taxa_di_1y*100:.2f}%
    </div>
    """, unsafe_allow_html=True)

if pagina == "Otimiza√ß√£o":
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üîê Acesso Comdinheiro")
    api_user = st.sidebar.text_input("Usu√°rio", value=st.session_state.get('api_user', 'InteligenciaGhia'))
    api_pass = st.sidebar.text_input("Senha", type="password", value=st.session_state.get('api_pass', 'InteligenciaGhia'))
    st.session_state['api_user'] = api_user
    st.session_state['api_pass'] = api_pass

# --- 6. CONTE√öDO ---

# === P√ÅGINA 1: BENCHMARK ===
if pagina == "Benchmark":
    st.title("Defini√ß√£o de Benchmark de Rentabilidade")
    
    st.markdown("""
    Esta etapa estabelece o **benchmark com base no juro real** que servir√° de base para as metas das carteiras.
    O c√°lculo combina o hist√≥rico (juro real Ex-Post) com as expectativas atuais de mercado (juro real Ex-Ante).
    """)
    
    st.divider()

    # --- Bloco A: Diagn√≥stico ---
    st.subheader("1. Diagn√≥stico de Juro Real")
    
    if not df_hist.empty:
        media_total_ex_post = df_hist['Juro_Real_12m'].mean()
        media_5y_ex_post = df_hist['Juro_Real_12m'].iloc[-60:].mean()
        atual_ex_post = df_hist['Juro_Real_12m'].iloc[-1]
        data_ultimo = df_hist.index[-1].strftime('%m/%Y')
    else:
        media_total_ex_post = 0; media_5y_ex_post = 0; atual_ex_post = 0; data_ultimo = "-"

    col_left, col_right = st.columns(2)
    
    with col_left:
        st.info("**Vis√£o Hist√≥rica (Ex-Post)**\n\nRetorno acumulado de 12 meses do CDI descontado pelo IPCA realizado no mesmo per√≠odo.")
        c1, c2, c3 = st.columns(3)
        c1.metric(
            "M√©dia Desde 2005", 
            f"{media_total_ex_post*100:.2f}%",
            help="M√©dia aritm√©tica simples do juro real ex-post de todos os meses desde janeiro/2005. Representa o retorno m√©dio hist√≥rico do CDI acima da infla√ß√£o em per√≠odos normais e de crise."
        )
        c2.metric(
            "M√©dia 5 Anos", 
            f"{media_5y_ex_post*100:.2f}%", 
            help="M√©dia m√≥vel dos √∫ltimos 60 meses (5 anos). Captura tend√™ncias mais recentes e √© menos influenciada por per√≠odos antigos de juro real elevado (2015-2016). Recomendada para benchmarks de m√©dio prazo."
        )
        c3.metric(
            f"Atual ({data_ultimo})", 
            f"{atual_ex_post*100:.2f}%", 
            delta=f"{(atual_ex_post - media_5y_ex_post)*100:.2f} p.p vs m√©dia",
            help=f"Juro real realizado nos √∫ltimos 12 meses (acumulado m√≥vel at√© {data_ultimo}). Calculado como: [(1+CDI acum)/(1+IPCA acum)] - 1. O delta mostra quantos pontos percentuais est√° acima/abaixo da m√©dia de 5 anos."
        )

    with col_right:
        st.warning(f"**Vis√£o Mercado (Ex-Ante)**\n\nExpectativa impl√≠cita na Curva de Juros ANBIMA e IPCA esperado pelo mercado.")
        c4, c5 = st.columns(2)
        c4.metric(
            "DI Futuro (1Y)", 
            f"{taxa_di_1y*100:.2f}%", 
            help=f"Taxa pr√©-fixada extra√≠da da Estrutura a Termo da Taxa de Juros (ETTJ) da ANBIMA para o v√©rtice de 365 dias corridos. Representa a expectativa do mercado para o CDI m√©dio nos pr√≥ximos 12 meses. Data: {data_ettj}"
        )
        c5.metric(
            "IPCA Focus (12m)", 
            f"{expectativa_ipca*100:.2f}%", 
            help="Mediana das expectativas de infla√ß√£o para os pr√≥ximos 12 meses coletadas pelo Banco Central no Boletim Focus. Atualizado semanalmente com as proje√ß√µes de cerca de 100 institui√ß√µes financeiras."
        )
        st.metric(
            "Juro Real Ex-Ante (1Y)", 
            f"{taxa_real_ex_ante*100:.2f}%", 
            delta="Taxa de Mercado",
            help=f"Taxa real (DI x IPCA) impl√≠cita na curva ANBIMA para o v√©rtice de 252 dias √∫teis (1 ano). Extra√≠da diretamente da ETTJ IPCA, reflete a expectativa do mercado de juro real para os pr√≥ximos 12 meses. Data: {data_real_exante}"
        )

    st.divider()

    # --- Bloco B: Defini√ß√£o do Target ---
    st.subheader("2. Defini√ß√£o do Target")
    st.markdown("""
    Defina o peso atribu√≠do ao hist√≥rico versus a expectativa de mercado para compor o **Benchmark H√≠brido**.
    Carteiras de longo prazo tendem a atribuir maior peso √† m√©dia hist√≥rica para evitar volatilidade de meta.
    """)
    
    # Carrega configura√ß√µes salvas ou usa defaults
    default_benchmark_config = {
        'periodo_historico': '5 Anos',
        'peso_hist': 50.0,
        'override': False,
        'valor_manual': 6.0,
        'usar_di_futuro': False
    }
    saved_benchmark_config = st.session_state.get('benchmark_config_salvo', default_benchmark_config)
    
    # Op√ß√£o de usar DI Futuro 1Y como benchmark
    usar_di_futuro = st.checkbox(
        "üìä Usar DI Futuro (1Y) como Benchmark",
        value=saved_benchmark_config.get('usar_di_futuro', False),
        key="usar_di_futuro_checkbox",
        help=f"Quando marcado, o benchmark ser√° o DI Futuro 1Y ({taxa_di_1y*100:.2f}%) ao inv√©s do c√°lculo h√≠brido. Os targets das carteiras ser√£o: Conservador = DI+1pp, Moderado = DI+2pp, Agressivo = DI+3pp."
    )
    
    st.session_state['usar_di_futuro'] = usar_di_futuro
    
    col_in1, col_in2 = st.columns([1, 2])
    with col_in1:
        st.markdown("**Pondera√ß√£o**")
        
        # Sele√ß√£o do per√≠odo hist√≥rico
        periodo_historico = st.radio(
            "Per√≠odo Hist√≥rico de Refer√™ncia:",
            options=['5 Anos', 'Per√≠odo Completo (Desde 2005)'],
            index=0 if saved_benchmark_config['periodo_historico'] == '5 Anos' else 1,
            key="periodo_historico",
            disabled=usar_di_futuro
        )
        
        # Define qual m√©dia usar baseado na sele√ß√£o
        if periodo_historico == '5 Anos':
            media_hist_selecionada = media_5y_ex_post
            label_periodo = "5 Anos"
        else:
            media_hist_selecionada = media_total_ex_post
            label_periodo = "Per√≠odo Completo"
        
        peso_hist = st.slider("Peso Hist√≥rico (%)", 0, 100, int(saved_benchmark_config['peso_hist']), 5, key="peso_hist_slider", disabled=usar_di_futuro) / 100
        peso_mkt = 1 - peso_hist
        if not usar_di_futuro:
            st.caption(f"Hist√≥rico ({label_periodo}): {peso_hist*100:.0f}% | Mercado (Ex-Ante): {peso_mkt*100:.0f}%")
        else:
            st.caption("‚ö†Ô∏è Pondera√ß√£o desabilitada - usando DI Futuro 1Y")
    
    if usar_di_futuro:
        # Usa DI Futuro 1Y nominal (PRE) direto da ETTJ 252 dias √∫teis
        benchmark_calc = taxa_di_1y
    else:
        benchmark_calc = (media_hist_selecionada * peso_hist) + (taxa_real_ex_ante * peso_mkt)
    
    with col_in2:
        if usar_di_futuro:
            st.markdown("**Benchmark: DI Futuro (1Y)**")
            st.metric(
                "Target Base (DI 1Y Nominal - PRE)", 
                f"{benchmark_calc*100:.2f}%",
                delta="DI Futuro PRE",
                help=f"Benchmark baseado no DI Futuro 1Y ({taxa_di_1y*100:.2f}% nominal) extra√≠do da ETTJ PRE para 252 dias √∫teis. Os perfis usar√£o: Conservador = DI+1pp, Moderado = DI+2pp, Agressivo = DI+3pp."
            )
        else:
            st.markdown("**Benchmark Calculado (IPCA + X%)**")
            st.metric(
                "Target Final Sugerido", 
                f"{benchmark_calc*100:.2f}%",
                help=f"Meta de juro real h√≠brida calculada como: ({peso_hist*100:.0f}% √ó {media_hist_selecionada*100:.2f}% hist√≥rico) + ({peso_mkt*100:.0f}% √ó {taxa_real_ex_ante*100:.2f}% mercado). Esta ser√° a meta de retorno real das carteiras (IPCA + X%). Carteiras conservadoras ter√£o meta inferior, agressivas superior."
            )
        
        override = st.checkbox(
            "Sobrepor valor calculado manualmente?", 
            value=saved_benchmark_config['override'], 
            key="override_checkbox",
            disabled=usar_di_futuro,
            help="Marque esta op√ß√£o para ignorar o c√°lculo autom√°tico e definir uma meta customizada. √ötil quando voc√™ tem uma expectativa espec√≠fica que difere do modelo."
        )
        if override:
            benchmark_final = st.number_input(
                "Target Manual (%)", 
                value=float(saved_benchmark_config['valor_manual']), 
                key="valor_manual_input",
                help="Meta de juro real customizada em % ao ano. Exemplo: 6.0% significa meta de IPCA + 6% a.a."
            ) / 100
        else:
            benchmark_final = benchmark_calc

    st.session_state['benchmark_final'] = benchmark_final
    
    # Bot√µes salvar/restaurar benchmark
    col_save_bench, col_reset_bench = st.columns([1, 1])
    with col_save_bench:
        if st.button("üíæ Salvar Configura√ß√£o do Benchmark", use_container_width=True, key="save_benchmark"):
            st.session_state['benchmark_config_salvo'] = {
                'periodo_historico': periodo_historico,
                'peso_hist': peso_hist * 100,
                'override': override,
                'valor_manual': benchmark_final * 100 if override else benchmark_calc * 100,
                'usar_di_futuro': usar_di_futuro
            }
            st.success("‚úÖ Configura√ß√£o do Benchmark salva!")
            st.rerun()
    with col_reset_bench:
        if st.button("üîÑ Restaurar Padr√µes", use_container_width=True, key="reset_benchmark"):
            if 'benchmark_config_salvo' in st.session_state:
                del st.session_state['benchmark_config_salvo']
                st.success("‚úÖ Configura√ß√£o padr√£o restaurada!")
                st.rerun()
    
    if not df_hist.empty:
        st.markdown("**Evolu√ß√£o Hist√≥rica do Juro Real (Janela M√≥vel 12 Meses)**")
        st.line_chart(df_hist['Juro_Real_12m'] * 100)

# === P√ÅGINA 2: CEN√ÅRIOS ===
elif pagina == "Cen√°rios Macro":
    st.title("Premissas e Cen√°rios Macroecon√¥micos")
    
    bench_ref = st.session_state.get('benchmark_final', 0.06)
    st.info(f"O Benchmark definido na etapa anterior foi **IPCA + {bench_ref*100:.2f}%**. As proje√ß√µes abaixo devem buscar consist√™ncia com este alvo.")

    st.markdown("""
    Esta etapa utiliza uma abordagem **Top-Down**. Primeiro, definimos os cen√°rios para as vari√°veis macroecon√¥micas (Drivers).
    Em seguida, o modelo calcula automaticamente o retorno esperado de cada classe de ativo aplicando regras de spread e marca√ß√£o a mercado.
    """)

    st.subheader("1. Probabilidades dos Cen√°rios")
    st.caption("Distribui√ß√£o de probabilidade para os cen√°rios Bear, Neutro e Bull nos pr√≥ximos 12 meses.")
    
    # Carrega valores salvos ou usa defaults
    default_probs = {'bear': 45.0, 'neutro': 10.0, 'bull': 45.0}
    saved_probs = st.session_state.get('probabilidades_salvas', default_probs)
    
    col_prob1, col_prob2, col_prob3, col_check = st.columns(4)
    with col_prob1: 
        prob_bear = st.number_input(
            "Prob. Bear (%)", 
            0.0, 100.0, saved_probs['bear'], 5.0, 
            key="prob_bear",
            help="Probabilidade de ocorr√™ncia do cen√°rio pessimista (Bear). Considera recess√£o, crise pol√≠tica, aperto monet√°rio severo, fuga de capital, etc."
        ) / 100
    with col_prob2: 
        prob_neutro = st.number_input(
            "Prob. Neutro (%)", 
            0.0, 100.0, saved_probs['neutro'], 5.0, 
            key="prob_neutro",
            help="Probabilidade de manuten√ß√£o do status quo. Crescimento moderado, infla√ß√£o controlada, sem grandes mudan√ßas macroecon√¥micas."
        ) / 100
    with col_prob3: 
        prob_bull = st.number_input(
            "Prob. Bull (%)", 
            0.0, 100.0, saved_probs['bull'], 5.0, 
            key="prob_bull",
            help="Probabilidade do cen√°rio otimista (Bull). Reforma estrutural, acelera√ß√£o do crescimento, queda de juros, melhora fiscal, rally de ativos."
        ) / 100
    
    soma = prob_bear + prob_neutro + prob_bull
    with col_check:
        st.markdown("**Valida√ß√£o**")
        if abs(soma - 1.0) < 0.01: st.success("Soma: 100%")
        else: st.error(f"Soma: {soma*100:.0f}% (Ajuste)")
    
    # Bot√µes salvar/restaurar probabilidades
    col_save_prob, col_reset_prob = st.columns([1, 1])
    with col_save_prob:
        if st.button("üíæ Salvar Probabilidades", use_container_width=True, key="save_prob"):
            st.session_state['probabilidades_salvas'] = {
                'bear': prob_bear * 100,
                'neutro': prob_neutro * 100,
                'bull': prob_bull * 100
            }
            st.success("‚úÖ Probabilidades salvas!")
            st.rerun()
    with col_reset_prob:
        if st.button("üîÑ Restaurar Padr√µes", use_container_width=True, key="reset_prob"):
            if 'probabilidades_salvas' in st.session_state:
                del st.session_state['probabilidades_salvas']
                st.success("‚úÖ Probabilidades padr√£o restauradas!")
                st.rerun()

    st.divider()

    st.subheader("2. Par√¢metros de Mercado")
    st.markdown("""
    Para calcular o ganho ou perda de capital (fechamento/abertura de curva) na Renda Fixa Pr√© e IPCA, 
    √© necess√°rio comparar as taxas projetadas nos cen√°rios com as taxas de mercado vigentes hoje, considerando a duration.
    """)
    
    # Info sobre as taxas da ETTJ
    st.info(f"üìä Taxas atualizadas da ETTJ: Pr√© 504d ({st.session_state['data_pre_504']}) = {st.session_state['taxa_pre_504']*100:.2f}% | "
           f"Real 1638d ({st.session_state['data_real_1638']}) = {st.session_state['taxa_real_1638']*100:.2f}%")
    
    # Debug ETTJ
    with st.expander("üîç Debug ETTJ (Investigar discrep√¢ncias)", expanded=False):
        # Bot√£o para limpar cache e recarregar taxas ETTJ
        if st.button("üîÑ Limpar Cache e Recarregar Taxas ETTJ"):
            get_taxa_pre_vertice_504.clear()
            get_taxa_real_vertice_1638.clear()
            if 'taxa_pre_504' in st.session_state:
                del st.session_state['taxa_pre_504']
            if 'taxa_real_1638' in st.session_state:
                del st.session_state['taxa_real_1638']
            st.rerun()
        
        if 'debug_ettj_pre' in st.session_state:
            st.write("**Taxa Pr√© (504 dias):**")
            debug_pre = st.session_state['debug_ettj_pre']
            st.write(f"Data: {debug_pre['data']}")
            st.write(f"Colunas dispon√≠veis: {debug_pre['colunas']}")
            st.write(f"V√©rtice 504 existe exato? {debug_pre.get('vertice_504_existe', 'N/A')}")
            st.write(f"Taxa retornada: {debug_pre.get('taxa_retornada', 'N/A')}")
            st.write(f"Foi interpolado? {debug_pre.get('foi_interpolado', 'N/A')}")
            st.write(f"Range dias: {debug_pre.get('min_dias', '?')} - {debug_pre.get('max_dias', '?')}")
            if 'vertice_504_row' in debug_pre and debug_pre['vertice_504_row']:
                st.write("V√©rtice 504 encontrado:")
                st.json(debug_pre['vertice_504_row'])
            st.write("Curva completa (sample):")
            if 'sample_completo' in debug_pre:
                st.dataframe(pd.DataFrame(debug_pre['sample_completo']))
        else:
            st.info("Debug vazio. Clique no bot√£o acima para recarregar as taxas ETTJ.")
        
        if 'debug_ettj_real' in st.session_state:
            st.write("**Taxa Real (1638 dias):**")
            debug_real = st.session_state['debug_ettj_real']
            st.write(f"Data: {debug_real['data']}")
            st.write(f"Colunas dispon√≠veis: {debug_real['colunas']}")
            st.write(f"V√©rtice 1638 existe exato? {debug_real.get('vertice_1638_existe', 'N/A')}")
            st.write(f"Taxa retornada: {debug_real.get('taxa_retornada', 'N/A')}")
            st.write(f"Foi interpolado? {debug_real.get('foi_interpolado', 'N/A')}")
            st.write(f"Range dias: {debug_real.get('min_dias', '?')} - {debug_real.get('max_dias', '?')}")
            if 'vertice_1638_row' in debug_real and debug_real['vertice_1638_row']:
                st.write("V√©rtice 1638 encontrado:")
                st.json(debug_real['vertice_1638_row'])
            st.write("Curva completa (sample):")
            if 'sample_completo' in debug_real:
                st.dataframe(pd.DataFrame(debug_real['sample_completo']))
        
        if 'debug_ettj_pre_error' in st.session_state:
            st.error(f"Erro Pr√©: {st.session_state['debug_ettj_pre_error']}")
        if 'debug_ettj_real_error' in st.session_state:
            st.error(f"Erro Real: {st.session_state['debug_ettj_real_error']}")
    
    # Carrega valores salvos ou usa defaults (agora com taxas da ETTJ)
    default_params = {
        'taxa_pre': st.session_state['taxa_pre_504']*100,  # V√©rtice 504
        'duration_pre': 2.0,
        'taxa_real': st.session_state['taxa_real_1638']*100,  # V√©rtice 1638
        'duration_imab': 6.53
    }
    saved_params = st.session_state.get('parametros_mercado_salvos', default_params)
    
    with st.expander("Expandir Configura√ß√µes de Taxas e Duration", expanded=True):
        col_mkt1, col_mkt2, col_mkt3, col_mkt4 = st.columns(4)
        taxa_pre_mercado = col_mkt1.number_input(
            "Taxa Pr√© (Nominal) Hoje %", 
            value=saved_params['taxa_pre'], 
            format="%.2f", 
            key="taxa_pre", 
            help="Taxa pr√©-fixada de mercado extra√≠da do v√©rtice 504 dias √∫teis da ETTJ ANBIMA. Usada como refer√™ncia para calcular ganho/perda de capital no IRF-M quando a curva se move nos cen√°rios."
        )
        duration_pre = col_mkt2.number_input(
            "Duration Pr√© (Anos)", 
            value=saved_params['duration_pre'], 
            key="dur_pre",
            help="Duration modificada da carteira de t√≠tulos pr√©-fixados (IRF-M). Representa a sensibilidade do pre√ßo a varia√ß√µes de 1% na taxa. Exemplo: Duration 2 anos ‚Üí queda de 1% na taxa = ganho de 2% no pre√ßo."
        )
        taxa_real_mercado = col_mkt3.number_input(
            "Taxa Real (NTN-B) Hoje %", 
            value=saved_params['taxa_real'], 
            format="%.2f", 
            key="taxa_real", 
            help="Taxa real (IPCA+) de mercado extra√≠da do v√©rtice 1638 dias √∫teis da ETTJ ANBIMA (DI x IPCA 252). Usada para calcular marca√ß√£o a mercado do IMA-B quando a taxa real muda nos cen√°rios."
        )
        duration_imab = col_mkt4.number_input(
            "Duration IMA-B (Anos)", 
            value=saved_params['duration_imab'], 
            key="dur_imab",
            help="Duration modificada da carteira de t√≠tulos indexados ao IPCA (IMA-B). Sensibilidade do pre√ßo a varia√ß√µes de 1% na taxa real. Exemplo: Duration 6.5 anos ‚Üí queda de 1% na taxa real = ganho de 6.5% no pre√ßo."
        )
    
    # Bot√µes salvar/restaurar par√¢metros
    col_save_params, col_reset_params = st.columns([1, 1])
    with col_save_params:
        if st.button("üíæ Salvar Par√¢metros", use_container_width=True, key="save_params"):
            st.session_state['parametros_mercado_salvos'] = {
                'taxa_pre': taxa_pre_mercado,
                'duration_pre': duration_pre,
                'taxa_real': taxa_real_mercado,
                'duration_imab': duration_imab
            }
            st.success("‚úÖ Par√¢metros salvos!")
            st.rerun()
    with col_reset_params:
        if st.button("üîÑ Restaurar Padr√µes", use_container_width=True, key="reset_params"):
            if 'parametros_mercado_salvos' in st.session_state:
                del st.session_state['parametros_mercado_salvos']
                st.success("‚úÖ Par√¢metros padr√£o restaurados!")
                st.rerun()

    st.subheader("3. Premissas Macroecon√¥micas")
    st.caption("Preencha as expectativas para as vari√°veis-chave em cada cen√°rio. Estas premissas alimentar√£o o pricing dos ativos.")
    
    # Carrega valores salvos ou usa defaults
    drivers = ["CDI", "IPCA", "Juro Real (NTN-B)", "Juro Nominal (2 anos)", "Ibovespa (Nominal)", "IFIX (Nominal)"]
    default_macro = pd.DataFrame(index=drivers)
    default_macro['Bear'] = [14.50, 5.50, 8.50, 15.0, -20.0, -10.0]
    default_macro['Neutro'] = [13.00, 4.00, 7.35, 13.0, 20.0, 10.0]
    default_macro['Bull'] = [11.00, 3.80, 5.50, 10.0, 40.0, 25.0]
    
    if 'drivers_macro_salvos' in st.session_state:
        df_macro = st.session_state['drivers_macro_salvos'].copy()
    else:
        df_macro = default_macro.copy()

    df_macro_edit = st.data_editor(df_macro, use_container_width=True, key="drivers_macro")
    
    # Bot√µes salvar/restaurar drivers
    col_save_drivers, col_reset_drivers = st.columns([1, 1])
    with col_save_drivers:
        if st.button("üíæ Salvar premissas", use_container_width=True, key="save_drivers"):
            st.session_state['drivers_macro_salvos'] = df_macro_edit.copy()
            st.success("‚úÖ Premissas macroecon√¥micas salvas!")
            st.rerun()
    with col_reset_drivers:
        if st.button("üîÑ Restaurar Padr√µes", use_container_width=True, key="reset_drivers"):
            if 'drivers_macro_salvos' in st.session_state:
                del st.session_state['drivers_macro_salvos']
                st.success("‚úÖ Premissas padr√£o restauradas!")
                st.rerun()

    def calcular_retornos(cenario_dict, nome_cenario):
        cdi = cenario_dict['CDI'] / 100
        ipca = cenario_dict['IPCA'] / 100
        juro_real_cenario = cenario_dict['Juro Real (NTN-B)'] / 100
        juro_nominal_cenario = cenario_dict['Juro Nominal (2 anos)'] / 100
        ibov = cenario_dict['Ibovespa (Nominal)'] / 100
        ifix = cenario_dict['IFIX (Nominal)'] / 100
        
        diff_taxa_real = (taxa_real_mercado/100) - juro_real_cenario
        ganho_capital_real = duration_imab * diff_taxa_real
        r_imab = ((1 + ganho_capital_real) * (1 + juro_real_cenario) * (1 + ipca)) - 1
        
        diff_taxa_pre = (taxa_pre_mercado/100) - juro_nominal_cenario
        ganho_capital_pre = duration_pre * diff_taxa_pre
        r_irfm = ((1 + ganho_capital_pre) * (1 + juro_nominal_cenario)) - 1
        
        return {
            "CDI (Caixa)": cdi,
            "IDA-DI (Cr√©dito)": cdi * (1 + 0.01),
            "IMA-B (Infla√ß√£o)": r_imab,
            "IRF-M (Pr√©-fixado)": r_irfm,
            "IHFA (Multimercado)": cdi * 1.15,
            "IBOV (A√ß√µes BR)": ibov,
            "IFIX (FIIs)": ifix,
            "IMA-B 5+ (Il√≠quidos)": ((1 + 0.12) * (1 + ipca)) - 1,
        }

    resultados = {}
    for cen in ['Bear', 'Neutro', 'Bull']:
        resultados[cen] = calcular_retornos(df_macro_edit[cen].to_dict(), cen)

    df_ativos = pd.DataFrame(resultados)
    df_ativos['Retorno Esperado (%)'] = ((df_ativos['Bear']*prob_bear) + (df_ativos['Neutro']*prob_neutro) + (df_ativos['Bull']*prob_bull)) * 100
    
    for col in ['Bear', 'Neutro', 'Bull']:
        df_ativos[col] = df_ativos[col] * 100
        
    st.divider()
    
    st.subheader("4. Matriz de Retornos Projetada")
    st.markdown("""
    A tabela abaixo apresenta a rentabilidade nominal esperada para cada classe de ativo, derivada dos cen√°rios macro acima.
    O **Retorno Esperado (Ponderado)** ser√° utilizado como input para a otimiza√ß√£o de Markowitz.
    """)
    
    st.dataframe(
        df_ativos,
        column_config={
            "Retorno Esperado (%)": st.column_config.ProgressColumn(
                "Retorno Esperado (Ponderado)",
                format="%.2f%%",
                min_value=-5,
                max_value=25,
                help="M√©dia ponderada pelas probabilidades dos cen√°rios",
            ),
            "Bear": st.column_config.NumberColumn(format="%.2f%%"),
            "Neutro": st.column_config.NumberColumn(format="%.2f%%"),
            "Bull": st.column_config.NumberColumn(format="%.2f%%"),
        },
        use_container_width=True
    )
    
    st.session_state['premissas_retorno'] = df_ativos

# === P√ÅGINA 3: OTIMIZA√á√ÉO ===
elif pagina == "Otimiza√ß√£o":
    st.title("Otimiza√ß√£o de Portf√≥lio")
    
    if 'premissas_retorno' not in st.session_state:
        st.error("‚ö†Ô∏è Aten√ß√£o: Voc√™ precisa definir os Cen√°rios na Fase B antes de prosseguir.")
        st.stop()
        
    df_premissas = st.session_state['premissas_retorno']
    bench_base = st.session_state.get('benchmark_final', 0.06)
    
    # Seletor de M√âTODO principal
    st.markdown("### üéØ M√©todo de Otimiza√ß√£o")
    metodo_principal = st.radio(
        "Escolha o m√©todo:",
        options=["Markowitz (MVO)", "Black-Litterman", "Risk Parity"],
        help="""
        **Markowitz**: Otimiza√ß√£o cl√°ssica baseada em retorno/risco hist√≥rico
        **Black-Litterman**: Combina equil√≠brio de mercado com suas views subjetivas
        **Risk Parity**: Equaliza contribui√ß√£o de risco (ignora retornos esperados)
        """,
        horizontal=True
    )
    
    # Sub-op√ß√µes para Markowitz
    if metodo_principal == "Markowitz (MVO)":
        modo_markowitz = st.radio(
            "Crit√©rio de otimiza√ß√£o:",
            options=["M√°ximo Sharpe Ratio", "M√≠nima Vari√¢ncia"],
            help="**M√°ximo Sharpe Ratio**: Melhor rela√ß√£o retorno/risco | **M√≠nima Vari√¢ncia**: Menor volatilidade",
            horizontal=True,
            key="modo_markowitz"
        )
    
    # === EXPLICA√á√ÉO DOS M√âTODOS ===
    with st.expander("üìñ Entenda os M√©todos de Otimiza√ß√£o", expanded=False):
        st.markdown("""
        ### **1. Markowitz (Mean-Variance Optimization)**
        - **Input**: Retornos esperados + Matriz de covari√¢ncia
        - **Output**: Carteira que maximiza Sharpe ou minimiza vari√¢ncia
        - **Pr√≥s**: Simples, intuitivo, base da teoria moderna de portf√≥lio
        - **Contras**: Sens√≠vel a erros nas estimativas de retorno (garbage in, garbage out)
        
        ---
        
        ### **2. Black-Litterman**
        - **Input**: Equil√≠brio de mercado (market caps) + Views subjetivas do gestor + Covari√¢ncia
        - **Output**: Retornos ajustados que combinam mercado e opini√£o, aplicados no Markowitz
        - **Pr√≥s**: Incorpora views qualitativas, reduz extremos, mais est√°vel
        - **Contras**: Requer defini√ß√£o de market caps e confian√ßa nas views
        - **Quando usar**: Quando voc√™ tem convic√ß√µes fortes sobre alguns ativos (ex: "IBOV vai render 20%")
        
        ---
        
        ### **3. Risk Parity**
        - **Input**: Apenas matriz de covari√¢ncia (ignora retornos esperados!)
        - **Output**: Carteira onde cada ativo contribui igualmente para o risco total
        - **Pr√≥s**: N√£o depende de estimativas de retorno, muito est√°vel, bom para diversifica√ß√£o
        - **Contras**: Pode alocar muito em ativos de baixo retorno/baixa volatilidade
        - **Quando usar**: Quando n√£o confia nas proje√ß√µes de retorno ou busca m√°xima diversifica√ß√£o
        
        ---
        
        **üí° Dica**: Rode os 3 m√©todos e compare os resultados! Muitos gestores usam uma combina√ß√£o dos tr√™s.
        """)
    
    st.markdown("""
    Esta etapa calcula a aloca√ß√£o √≥tima utilizando as premissas de retorno definidas na Fase B
    e uma matriz de covari√¢ncia hist√≥rica para estimar o risco.
    """)
    
    st.divider()
    
    # === BLACK-LITTERMAN: Interface para Views ===
    if metodo_principal == "Black-Litterman":
        st.markdown("### üìù Defini√ß√£o de Views (Black-Litterman)")
        st.markdown("""
        Defina suas expectativas (views) sobre o desempenho de ativos espec√≠ficos.
        O modelo combinar√° suas views com o equil√≠brio de mercado para gerar retornos ajustados.
        """)
        
        ativos = df_premissas.index.tolist()
        
        # Pesos de equil√≠brio (market caps) - pode ser ajustado manualmente
        st.subheader("Pesos de Equil√≠brio (Market Cap)")
        st.caption("Distribua 100% entre os ativos conforme a representatividade de mercado.")
        
        default_market_caps = [0.0, 30.0, 25.0, 10.0, 10.0, 15.0, 5.0, 5.0]  # Exemplo
        
        if 'market_caps_bl' not in st.session_state:
            st.session_state['market_caps_bl'] = default_market_caps
        
        df_market_caps = pd.DataFrame({
            "Ativo": ativos,
            "Market Cap (%)": st.session_state['market_caps_bl']
        })
        
        df_market_caps_edit = st.data_editor(
            df_market_caps,
            column_config={
                "Market Cap (%)": st.column_config.NumberColumn(min_value=0, max_value=100, format="%.1f%%")
            },
            use_container_width=True,
            hide_index=True,
            key="market_caps_editor"
        )
        
        soma_market = df_market_caps_edit['Market Cap (%)'].sum()
        if abs(soma_market - 100) > 0.1:
            st.error(f"‚ö†Ô∏è Soma dos Market Caps: {soma_market:.1f}% (deve ser 100%)")
        else:
            st.success(f"‚úì Soma: {soma_market:.1f}%")
            st.session_state['market_caps_bl'] = df_market_caps_edit['Market Cap (%)'].tolist()
        
        st.divider()
        
        # Interface para adicionar views
        st.subheader("Views Subjetivas")
        st.caption("Adicione suas expectativas de retorno para ativos espec√≠ficos (ex: 'IBOV vai render 20% no pr√≥ximo ano')")
        
        # Inicializa lista de views
        if 'bl_views' not in st.session_state:
            st.session_state['bl_views'] = []
        
        # Formul√°rio para adicionar nova view
        with st.expander("‚ûï Adicionar Nova View", expanded=len(st.session_state['bl_views']) == 0):
            col_ativo, col_ret, col_conf = st.columns([2, 1, 1])
            view_ativo = col_ativo.selectbox("Ativo", ativos, key="new_view_ativo")
            view_retorno = col_ret.number_input("Retorno Esperado (%)", value=15.0, format="%.2f", key="new_view_ret")
            view_confianca = col_conf.slider("Confian√ßa", 1, 10, 5, help="1=Baixa, 10=Alta", key="new_view_conf")
            
            if st.button("Adicionar View", key="add_view_btn"):
                st.session_state['bl_views'].append({
                    'ativo': view_ativo,
                    'retorno': view_retorno,
                    'confianca': view_confianca
                })
                st.rerun()
        
        # Mostra views adicionadas
        if st.session_state['bl_views']:
            st.markdown("**Views Configuradas:**")
            for i, view in enumerate(st.session_state['bl_views']):
                col1, col2 = st.columns([4, 1])
                col1.info(f"**{view['ativo']}**: Retorno esperado de **{view['retorno']:.2f}%** (Confian√ßa: {view['confianca']}/10)")
                if col2.button("üóëÔ∏è", key=f"del_view_{i}"):
                    st.session_state['bl_views'].pop(i)
                    st.rerun()
        else:
            st.warning("‚ö†Ô∏è Nenhuma view configurada. O modelo usar√° apenas o equil√≠brio de mercado.")
    
    # === RISK PARITY: Configura√ß√µes ===
    elif metodo_principal == "Risk Parity":
        st.markdown("### ‚öñÔ∏è Configura√ß√µes Risk Parity")
        st.info("""
        Risk Parity equaliza a **contribui√ß√£o de risco** de cada ativo, n√£o seus pesos.
        Ativos menos vol√°teis ter√£o pesos maiores para equilibrar o risco total.
        """)
        
        use_vol_target = st.checkbox("Definir Target de Volatilidade", value=False, 
                                     help="Se marcado, ajusta alavancagem para atingir volatilidade espec√≠fica")
        
        if use_vol_target:
            vol_target_rp = st.number_input("Volatilidade Alvo (% a.a.)", value=8.0, min_value=1.0, max_value=30.0, format="%.1f") / 100
        else:
            vol_target_rp = None

    # 1. Defini√ß√£o de Perfil
    st.divider()
    st.markdown("### 1. Defini√ß√£o de Perfil e Restri√ß√µes")
    st.caption("Selecione o perfil de risco. O Target de Retorno e as restri√ß√µes de aloca√ß√£o ser√£o ajustados automaticamente.")
    
    col_perf, col_target = st.columns([1, 2])
    
    with col_perf:
        perfil_selecionado = st.radio("Selecione o Perfil:", ["Conservador", "Moderado", "Agressivo"])
    
    # Verifica se est√° usando DI Futuro como benchmark
    usar_di_futuro_opt = st.session_state.get('usar_di_futuro', False)
    
    if usar_di_futuro_opt:
        # Quando usa DI Futuro: Conservador = DI+1pp, Moderado = DI+2pp, Agressivo = DI+3pp
        if perfil_selecionado == "Conservador":
            target_final = bench_base + 0.01
            defaults_min = [0.0, 0.50, 0.10, 0.0, 0.05, 0.0, 0.0, 0.0]
            defaults_max = [0.0, 0.80, 0.40, 0.20, 0.20, 0.10, 0.0, 0.0]
            delta_str = "DI + 1.00 p.p."
            vol_min, vol_max = 0.01, 0.02  # 1% a 2%
        elif perfil_selecionado == "Moderado":
            target_final = bench_base + 0.02
            defaults_min = [0.0, 0.20, 0.10, 0.0, 0.05, 0.05, 0.05, 0.0]
            defaults_max = [0.0, 0.60, 0.40, 0.20, 0.25, 0.20, 0.10, 0.10]
            delta_str = "DI + 2.00 p.p."
            vol_min, vol_max = 0.03, 0.04  # 3% a 4%
        else: # Agressivo
            target_final = bench_base + 0.03
            defaults_min = [0.0, 0.10, 0.10, 0.0, 0.05, 0.10, 0.05, 0.05]
            defaults_max = [0.0, 0.40, 0.40, 0.20, 0.30, 0.35, 0.15, 0.15]
            delta_str = "DI + 3.00 p.p."
            vol_min, vol_max = 0.05, 0.06  # 5% a 6%
    else:
        # Quando usa benchmark h√≠brido (padr√£o)
        if perfil_selecionado == "Conservador":
            target_final = bench_base - 0.01
            defaults_min = [0.0, 0.50, 0.10, 0.0, 0.05, 0.0, 0.0, 0.0]
            defaults_max = [0.0, 0.80, 0.40, 0.20, 0.20, 0.10, 0.0, 0.0]
            delta_str = "- 1.00 p.p."
            vol_min, vol_max = 0.01, 0.02  # 1% a 2%
        elif perfil_selecionado == "Moderado":
            target_final = bench_base
            defaults_min = [0.0, 0.20, 0.10, 0.0, 0.05, 0.05, 0.05, 0.0]
            defaults_max = [0.0, 0.60, 0.40, 0.20, 0.25, 0.20, 0.10, 0.10]
            delta_str = "Benchmark"
            vol_min, vol_max = 0.03, 0.04  # 3% a 4%
        else: # Agressivo
            target_final = bench_base + 0.01
            defaults_min = [0.0, 0.10, 0.10, 0.0, 0.05, 0.10, 0.05, 0.05]
            defaults_max = [0.0, 0.40, 0.40, 0.20, 0.30, 0.35, 0.15, 0.15]
            delta_str = "+ 1.00 p.p."
            vol_min, vol_max = 0.05, 0.06  # 5% a 6%
    
    # Armazena limites de volatilidade no session_state
    st.session_state['vol_min'] = vol_min
    st.session_state['vol_max'] = vol_max

    ipca_focus = expectativa_ipca
    
    # Quando usa DI Futuro, o target j√° est√° nominal, n√£o precisa somar IPCA
    if usar_di_futuro_opt:
        target_nominal = target_final
    else:
        target_nominal = ((1 + target_final) * (1 + ipca_focus)) - 1

    with col_target:
        if usar_di_futuro_opt:
            st.metric(
                label=f"Meta de Retorno Nominal ({perfil_selecionado})", 
                value=f"{target_final*100:.2f}%",
                delta=delta_str
            )
            st.caption(f"Meta Nominal (para o Solver): {target_nominal*100:.2f}%")
        else:
            st.metric(
                label=f"Meta de Retorno Real ({perfil_selecionado})", 
                value=f"{target_final*100:.2f}% + IPCA",
                delta=delta_str
            )
            st.caption(f"Meta Nominal Equivalente (para o Solver): {target_nominal*100:.2f}%")
        
        st.info(f"üìä **Banda de Volatilidade:** {vol_min*100:.0f}% a {vol_max*100:.0f}% a.a.")

    # Tabela de Constraints (com persist√™ncia por perfil)
    st.subheader(f"Limites de Aloca√ß√£o: {perfil_selecionado}")
    ativos = df_premissas.index.tolist()
    
    # Inicializa storage de restri√ß√µes se n√£o existir
    if 'constraints_por_perfil' not in st.session_state:
        st.session_state['constraints_por_perfil'] = {}
    
    # Carrega restri√ß√µes salvas ou usa defaults
    if perfil_selecionado in st.session_state['constraints_por_perfil']:
        df_constraints = st.session_state['constraints_por_perfil'][perfil_selecionado].copy()
    else:
        df_constraints = pd.DataFrame({
            "Ativo": ativos,
            "Min (%)": [x * 100 for x in defaults_min],
            "Max (%)": [x * 100 for x in defaults_max]
        })
    
    df_constraints_edit = st.data_editor(
        df_constraints,
        column_config={
            "Min (%)": st.column_config.NumberColumn(min_value=0, max_value=100, format="%.1f%%"),
            "Max (%)": st.column_config.NumberColumn(min_value=0, max_value=100, format="%.1f%%")
        },
        use_container_width=True, hide_index=True,
        key=f"constraints_{perfil_selecionado}"
    )
    
    # Bot√µes para gerenciar restri√ß√µes
    col_save, col_reset, col_unrestricted = st.columns([1, 1, 1])
    with col_save:
        if st.button("üíæ Salvar Restri√ß√µes", use_container_width=True):
            st.session_state['constraints_por_perfil'][perfil_selecionado] = df_constraints_edit.copy()
            st.success(f"‚úÖ Restri√ß√µes salvas para o perfil {perfil_selecionado}!")
            st.rerun()
    
    with col_reset:
        if st.button("üîÑ Restaurar Padr√µes", use_container_width=True):
            if perfil_selecionado in st.session_state['constraints_por_perfil']:
                del st.session_state['constraints_por_perfil'][perfil_selecionado]
                st.success(f"‚úÖ Restri√ß√µes padr√£o restauradas para {perfil_selecionado}!")
                st.rerun()
    
    with col_unrestricted:
        if st.button("üîì Sem Restri√ß√µes", use_container_width=True, help="Define Min=0% e Max=100% para todos os ativos"):
            df_unrestricted = df_constraints_edit.copy()
            df_unrestricted['Min (%)'] = 0.0
            df_unrestricted['Max (%)'] = 100.0
            st.session_state['constraints_por_perfil'][perfil_selecionado] = df_unrestricted
            st.success("‚úÖ Restri√ß√µes removidas (Min=0%, Max=100%)!")
            st.rerun()

    st.divider()

    # 2. Dados e C√°lculo
    st.markdown("### 2. Otimiza√ß√£o de Carteira")
    if metodo_principal == "Markowitz (MVO)":
        if modo_markowitz == "M√°ximo Sharpe Ratio":
            st.markdown("O sistema buscar√° a combina√ß√£o de ativos que **maximiza o Sharpe Ratio** (melhor rela√ß√£o retorno/risco) respeitando os limites definidos.")
        else:
            st.markdown("O sistema buscar√° a combina√ß√£o de ativos com **menor volatilidade poss√≠vel**, respeitando os limites definidos.")
    elif metodo_principal == "Black-Litterman":
        st.markdown("O modelo combinar√° suas views com o equil√≠brio de mercado para gerar aloca√ß√£o otimizada.")
    else:
        st.markdown("O modelo equalizar√° a **contribui√ß√£o de risco** de cada ativo na carteira.")
    
    # Bot√£o para baixar dados da API (uma vez s√≥)
    col_btn1, col_btn2 = st.columns([1, 1])
    with col_btn1:
        if st.button("üì• Baixar Dados da API", use_container_width=True):
            with st.spinner("Conectando Comdinheiro (Recuperando cota√ß√µes)..."):
                user = st.session_state.get('api_user')
                pwd = st.session_state.get('api_pass')
                df_returns_temp, msg = fetch_comdinheiro_data(user, pwd)
                
                # Mostrar dados brutos da API
                if 'api_full_response' in st.session_state:
                    with st.expander("üîç RESPOSTA COMPLETA DA API (Debug)", expanded=False):
                        full_resp = st.session_state['api_full_response']
                        st.error(f"‚ö†Ô∏è TAB-P0: {full_resp['total_rows_p0']} linhas | TAB-P1: {full_resp['total_rows_p1']} linhas")
                        st.write(f"**Chaves do JSON:** {full_resp['raw_json_keys']}")
                        st.write(f"**Chaves em 'resposta':** {full_resp['resposta_keys']}")
                
                if df_returns_temp is None:
                    st.error(f"Falha na API: {msg}")
                else:
                    # Armazena dados no session_state para reutiliza√ß√£o
                    st.session_state['df_returns_api'] = df_returns_temp
                    st.session_state['api_download_time'] = pd.Timestamp.now().strftime('%H:%M:%S')
                    st.success(f"‚úÖ Dados recuperados com sucesso! {msg}")
                    st.rerun()
    
    # Mostra status dos dados
    if 'df_returns_api' in st.session_state:
        st.info(f"‚úì Dados carregados √†s {st.session_state.get('api_download_time', 'N/A')} - {len(st.session_state['df_returns_api'])} dias")
    else:
        st.warning("‚ö†Ô∏è Dados n√£o carregados. Clique em 'Baixar Dados da API' primeiro.")
        st.stop()
    
    # Bot√£o para calcular otimiza√ß√£o (usa dados j√° baixados)
    with col_btn2:
        calcular_btn = st.button("üéØ Calcular Otimiza√ß√£o", type="secondary", use_container_width=True)
    
    if calcular_btn:
        with st.spinner("Calculando otimiza√ß√£o..."):
            # Usa os dados j√° carregados do session_state
            df_returns = st.session_state['df_returns_api']
            
            # ALINHAMENTO CR√çTICO: Garantir mesma ordem entre premissas e dados hist√≥ricos
            ativos_esperados = df_premissas.index.tolist()
            ativos_api = df_returns.columns.tolist()
            
            # Verifica se todos os ativos esperados est√£o na API
            ativos_faltantes = [a for a in ativos_esperados if a not in ativos_api]
            if ativos_faltantes:
                st.error(f"Ativos n√£o encontrados na API: {ativos_faltantes}")
                st.caption(f"Ativos dispon√≠veis: {ativos_api}")
                st.stop()
            
            # Reordena df_returns para corresponder √† ordem de df_premissas
            df_returns_aligned = df_returns[ativos_esperados]
            
            # Matriz Covari√¢ncia (Dados j√° s√£o retornos di√°rios, anualiza multiplicando por 252)
            cov_matrix = df_returns_aligned.cov() * 252
            
            # Prepara√ß√£o Solver - agora alinhados
            mu = df_premissas['Retorno Esperado (%)'].values / 100
            S = cov_matrix.values
            num_assets = len(mu)
            
            # Debug info (opcional - mostra para usu√°rio)
            with st.expander("üìä Informa√ß√µes de Debug", expanded=False):
                st.write(f"**Ativos (ordem):** {ativos_esperados}")
                st.write(f"**Retornos Esperados (mu):** {[f'{m*100:.2f}%' for m in mu]}")
                st.write(f"**Target Nominal:** {target_nominal*100:.2f}%")
                st.write(f"**Shape cov_matrix:** {S.shape}")
                st.write(f"**Dados hist√≥ricos:** {len(df_returns_aligned)} dias")
                
                st.write("**Amostra dos dados hist√≥ricos (√∫ltimos 5 dias):**")
                st.dataframe(df_returns_aligned.tail())
                
                st.write("**Estat√≠sticas dos retornos hist√≥ricos di√°rios:**")
                st.dataframe(df_returns_aligned.describe())
                
                st.write("**Diagonal da matriz de covari√¢ncia (vari√¢ncias anualizadas):**")
                variancias = np.diag(S)
                vols = np.sqrt(variancias)
                st.write({ativos_esperados[i]: f"{vols[i]*100:.2f}%" for i in range(len(ativos_esperados))})
            
            min_bounds = df_constraints_edit['Min (%)'].values / 100
            max_bounds = df_constraints_edit['Max (%)'].values / 100
            bounds = tuple(zip(min_bounds, max_bounds))
            
            def portfolio_vol(weights, cov_matrix):
                return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
            
            def neg_sharpe_ratio(weights, mu, cov_matrix, risk_free=0.0):
                """Sharpe Ratio negativo para minimiza√ß√£o (retorno - rf) / volatilidade"""
                ret = np.dot(weights, mu)
                vol = portfolio_vol(weights, cov_matrix)
                return -(ret - risk_free) / vol if vol > 0 else 1e10
            
            # Chute inicial: pesos iguais
            init_guess = num_assets * [1. / num_assets,]
            
            # Usa CDI como proxy de risk-free (m√©dia hist√≥rica anualizada)
            risk_free_rate = df_returns_aligned.iloc[:, 0].mean() * 252 if 'CDI' in ativos_esperados[0] else 0.0
            
            # 2.1. OTIMIZA√á√ÉO: Executa m√©todo selecionado
            try:
                # ========== M√âTODO 1: MARKOWITZ ==========
                if metodo_principal == "Markowitz (MVO)":
                    if modo_markowitz == "M√°ximo Sharpe Ratio":
                        # Maximizar Sharpe Ratio com restri√ß√µes de volatilidade
                        vol_min_perfil = st.session_state.get('vol_min', 0.01)
                        vol_max_perfil = st.session_state.get('vol_max', 0.10)
                        
                        constraints = [
                            {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},
                            {'type': 'ineq', 'fun': lambda x: portfolio_vol(x, S) - vol_min_perfil},  # vol >= vol_min
                            {'type': 'ineq', 'fun': lambda x: vol_max_perfil - portfolio_vol(x, S)}   # vol <= vol_max
                        ]
                        
                        opt_result = minimize(
                            neg_sharpe_ratio, 
                            init_guess, 
                            args=(mu, S, risk_free_rate), 
                            method='SLSQP', 
                            bounds=bounds, 
                            constraints=constraints,
                            options={'maxiter': 1000, 'ftol': 1e-9}
                        )
                    else:
                        # Minimizar Vari√¢ncia com restri√ß√µes de volatilidade
                        vol_min_perfil = st.session_state.get('vol_min', 0.01)
                        vol_max_perfil = st.session_state.get('vol_max', 0.10)
                        
                        constraints = [
                            {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},
                            {'type': 'ineq', 'fun': lambda x: portfolio_vol(x, S) - vol_min_perfil},  # vol >= vol_min
                            {'type': 'ineq', 'fun': lambda x: vol_max_perfil - portfolio_vol(x, S)}   # vol <= vol_max
                        ]
                        
                        opt_result = minimize(
                            portfolio_vol,
                            init_guess,
                            args=(S,),
                            method='SLSQP',
                            bounds=bounds,
                            constraints=constraints,
                            options={'maxiter': 1000, 'ftol': 1e-9}
                        )
                    
                    metodo_usado = f"Markowitz ({modo_markowitz})"
                
                # ========== M√âTODO 2: BLACK-LITTERMAN ==========
                elif metodo_principal == "Black-Litterman":
                    # Preparar inputs do Black-Litterman
                    market_caps = np.array(st.session_state['market_caps_bl']) / 100
                    
                    # Construir matriz de views (P) e vetor de retornos esperados (Q)
                    if st.session_state['bl_views']:
                        num_views = len(st.session_state['bl_views'])
                        P = np.zeros((num_views, num_assets))
                        Q = np.zeros(num_views)
                        omega_diag = np.zeros(num_views)
                        
                        for i, view in enumerate(st.session_state['bl_views']):
                            ativo_idx = ativos_esperados.index(view['ativo'])
                            P[i, ativo_idx] = 1.0  # View absoluta sobre um ativo
                            Q[i] = view['retorno'] / 100
                            # Omega: incerteza da view (inverso da confian√ßa)
                            omega_diag[i] = 0.01 / view['confianca']  # Quanto maior confian√ßa, menor incerteza
                        
                        omega = np.diag(omega_diag)
                    else:
                        # Sem views: usa apenas equil√≠brio de mercado (Pi)
                        P = np.zeros((1, num_assets))
                        P[0, 0] = 1.0  # View dummy
                        Q = np.array([0.0])
                        omega = np.diag([1e10])  # Incerteza infinita = ignora a view
                    
                    # Par√¢metro tau (incerteza no equil√≠brio)
                    tau = 0.025
                    
                    # Executa Black-Litterman
                    mu_bl = black_litterman(S, market_caps, tau, P, Q, omega)
                    
                    # Agora usa os retornos BL no Markowitz (M√°ximo Sharpe) com restri√ß√µes de volatilidade
                    vol_min_perfil = st.session_state.get('vol_min', 0.01)
                    vol_max_perfil = st.session_state.get('vol_max', 0.10)
                    
                    constraints = [
                        {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},
                        {'type': 'ineq', 'fun': lambda x: portfolio_vol(x, S) - vol_min_perfil},  # vol >= vol_min
                        {'type': 'ineq', 'fun': lambda x: vol_max_perfil - portfolio_vol(x, S)}   # vol <= vol_max
                    ]
                    
                    opt_result = minimize(
                        neg_sharpe_ratio, 
                        init_guess, 
                        args=(mu_bl, S, risk_free_rate), 
                        method='SLSQP', 
                        bounds=bounds, 
                        constraints=constraints,
                        options={'maxiter': 1000, 'ftol': 1e-9}
                    )
                    
                    # Atualiza mu para usar nos c√°lculos de retorno
                    mu = mu_bl
                    metodo_usado = "Black-Litterman"
                
                # ========== M√âTODO 3: RISK PARITY ==========
                elif metodo_principal == "Risk Parity":
                    # Risk Parity ignora restri√ß√µes de Min/Max e retornos esperados
                    weights_rp = risk_parity_optimization(S, vol_target_rp)
                    
                    # Cria objeto fake de resultado para compatibilidade
                    class FakeResult:
                        def __init__(self, x):
                            self.x = x
                            self.success = True
                            self.fun = 0
                    
                    opt_result = FakeResult(weights_rp)
                    metodo_usado = "Risk Parity"
                
                if opt_result.success:
                    weights_opt = opt_result.x
                    ret_otimo = np.dot(weights_opt, mu)
                    vol_otima = portfolio_vol(weights_opt, S)
                    sharpe_otimo = (ret_otimo - risk_free_rate) / vol_otima if vol_otima > 0 else 0
                    
                    # 2.2. GERA√á√ÉO DA FRONTEIRA
                    ret_min_possible = np.min(mu)
                    ret_max_possible = np.max(mu)
                    target_range = np.linspace(ret_min_possible, ret_max_possible, 20)
                    
                    frontier_vols = []
                    frontier_rets = []
                    
                    for t_ret in target_range:
                        cons_loop = (
                            {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}, 
                            {'type': 'eq', 'fun': lambda x: np.dot(x, mu) - t_ret}
                        )
                        res = minimize(portfolio_vol, init_guess, args=(S,), method='SLSQP', bounds=bounds, constraints=cons_loop)
                        if res.success:
                            frontier_vols.append(res.fun)
                            frontier_rets.append(t_ret)
                    
                    # --- PLOTAGEM ---
                    col_chart, col_data = st.columns([2, 1])
                    
                    with col_chart:
                        fig, ax = plt.subplots(figsize=(10, 5))
                        
                        # Fronteira eficiente (apenas para Markowitz e BL)
                        if metodo_principal != "Risk Parity":
                            ax.plot([v*100 for v in frontier_vols], [r*100 for r in frontier_rets], 'b--', label='Fronteira Eficiente')
                        
                        ax.scatter(vol_otima*100, ret_otimo*100, color='red', s=150, zorder=5, label=f'Carteira {perfil_selecionado}')
                        
                        # Marca o benchmark do perfil
                        ax.axhline(y=target_nominal*100, color='green', linestyle=':', linewidth=2, label='Benchmark Perfil')
                        
                        ax.set_title(f"Risco x Retorno ({perfil_selecionado}) - {metodo_usado}")
                        ax.set_xlabel("Volatilidade Esperada (% a.a.)")
                        ax.set_ylabel("Retorno Esperado (% a.a.)")
                        ax.legend()
                        ax.grid(True, alpha=0.3)
                        st.pyplot(fig)
                        
                    with col_data:
                        st.info(f"**M√©todo:** {metodo_usado}")
                        st.success(f"**Volatilidade:** {vol_otima*100:.2f}%")
                        st.metric("Retorno Otimizado", f"{ret_otimo*100:.2f}%", 
                                 delta=f"{(ret_otimo - target_nominal)*100:+.2f} p.p. vs target")
                        st.metric("Sharpe Ratio", f"{sharpe_otimo:.2f}")
                        
                        # Info adicional para Black-Litterman
                        if metodo_principal == "Black-Litterman":
                            st.caption(f"‚úì {len(st.session_state['bl_views'])} view(s) aplicada(s)")
                        
                        # Info adicional para Risk Parity
                        if metodo_principal == "Risk Parity":
                            st.caption("‚úì Contribui√ß√£o de risco equalizada")
                        
                        st.markdown("**Aloca√ß√£o Sugerida:**")
                        df_w = pd.DataFrame({"Ativo": ativos, "Peso": weights_opt*100})
                        
                        # Se Risk Parity, adiciona coluna de contribui√ß√£o de risco
                        if metodo_principal == "Risk Parity":
                            portfolio_var = weights_opt.T @ S @ weights_opt
                            portfolio_vol = np.sqrt(portfolio_var)
                            marginal_contrib = S @ weights_opt
                            risk_contrib = weights_opt * marginal_contrib / portfolio_vol if portfolio_vol > 0 else weights_opt * 0
                            risk_contrib_pct = (risk_contrib / np.sum(risk_contrib)) * 100 if np.sum(risk_contrib) > 0 else risk_contrib * 0
                            
                            df_w['Contribui√ß√£o Risco (%)'] = risk_contrib_pct
                            st.dataframe(
                                df_w.style.format({"Peso": "{:.2f}%", "Contribui√ß√£o Risco (%)": "{:.2f}%"})
                                    .background_gradient(subset=['Peso'], cmap="Blues")
                                    .background_gradient(subset=['Contribui√ß√£o Risco (%)'], cmap="Greens"),
                                use_container_width=True, hide_index=True
                            )
                        else:
                            st.dataframe(
                                df_w.style.format({"Peso": "{:.2f}%"}).background_gradient(cmap="Blues"),
                                use_container_width=True, hide_index=True
                            )
                    
                    # === MATRIZ DE CORRELA√á√ÉO (no final da p√°gina) ===
                    st.divider()
                    st.subheader("üìä Matriz de Correla√ß√£o Hist√≥rica dos Ativos")
                    st.markdown("""
                    Matriz de correla√ß√£o calculada com base nos retornos hist√≥ricos di√°rios.
                    Valores pr√≥ximos de **+1** indicam movimentos similares, **-1** indicam movimentos opostos, e **0** indica baixa correla√ß√£o.
                    """)
                    
                    df_returns_corr = st.session_state['df_returns_api']
                    
                    # Calcula matriz de correla√ß√£o
                    corr_matrix = df_returns_corr.corr()
                    
                    # Exibe com formata√ß√£o de heatmap
                    st.dataframe(
                        corr_matrix.style.background_gradient(cmap='RdYlGn', vmin=-1, vmax=1, axis=None)
                                         .format("{:.2f}"),
                        use_container_width=True
                    )
                    
                    # Estat√≠sticas adicionais
                    with st.expander("üìà An√°lise de Correla√ß√µes"):
                        st.write("**Pares com maior correla√ß√£o positiva:**")
                        # Pega tri√¢ngulo superior sem diagonal
                        upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
                        corr_pairs = upper_tri.stack().sort_values(ascending=False)
                        top_pos = corr_pairs.head(5)
                        for (idx1, idx2), val in top_pos.items():
                            st.write(f"‚Ä¢ {idx1} ‚Üî {idx2}: **{val:.3f}**")
                        
                        st.write("\n**Pares com maior correla√ß√£o negativa (diversifica√ß√£o):**")
                        top_neg = corr_pairs.tail(5)
                        for (idx1, idx2), val in top_neg.items():
                            st.write(f"‚Ä¢ {idx1} ‚Üî {idx2}: **{val:.3f}**")
                    
                    # --- BOT√ÉO PARA GERAR RELAT√ìRIO ---
                    st.markdown("---")
                    if st.button("üìÑ Gerar Relat√≥rio Completo", use_container_width=True, key="gerar_relatorio_btn"):
                        with st.spinner("Gerando relat√≥rio..."):
                            # Gera gr√°fico como imagem base64
                            buf = io.BytesIO()
                            fig.savefig(buf, format='png', dpi=150, bbox_inches='tight')
                            buf.seek(0)
                            img_base64 = base64.b64encode(buf.read()).decode()
                            
                            # Monta HTML do relat√≥rio
                            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                            html_content = f"""
                        <!DOCTYPE html>
                        <html>
                        <head>
                            <meta charset="UTF-8">
                            <title>Relat√≥rio Asset Allocation - {perfil_selecionado}</title>
                            <style>
                                body {{ font-family: Arial, sans-serif; margin: 40px; background: #f5f5f5; }}
                                .container {{ background: white; padding: 30px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
                                h1 {{ color: #1f77b4; border-bottom: 3px solid #1f77b4; padding-bottom: 10px; }}
                                h2 {{ color: #2c3e50; margin-top: 30px; border-bottom: 2px solid #e0e0e0; padding-bottom: 5px; }}
                                h3 {{ color: #34495e; margin-top: 20px; }}
                                table {{ border-collapse: collapse; width: 100%; margin: 15px 0; }}
                                th {{ background-color: #1f77b4; color: white; padding: 12px; text-align: left; }}
                                td {{ padding: 10px; border-bottom: 1px solid #ddd; }}
                                tr:hover {{ background-color: #f5f5f5; }}
                                .metric {{ display: inline-block; background: #e3f2fd; padding: 15px 20px; margin: 10px 10px 10px 0; 
                                         border-radius: 5px; border-left: 4px solid #1f77b4; }}
                                .metric-label {{ font-size: 12px; color: #666; }}
                                .metric-value {{ font-size: 24px; font-weight: bold; color: #1f77b4; }}
                                .chart {{ text-align: center; margin: 20px 0; }}
                                .footer {{ margin-top: 40px; padding-top: 20px; border-top: 2px solid #e0e0e0; 
                                          text-align: center; color: #666; font-size: 12px; }}
                            </style>
                        </head>
                        <body>
                            <div class="container">
                                <h1>üìä Relat√≥rio de Asset Allocation - {perfil_selecionado}</h1>
                                <p><strong>Data de Gera√ß√£o:</strong> {datetime.now().strftime("%d/%m/%Y %H:%M:%S")}</p>
                                <p><strong>M√©todo de Otimiza√ß√£o:</strong> {metodo_usado}</p>
                                
                                <h2>üéØ Resultados da Otimiza√ß√£o</h2>
                                <div>
                                    <div class="metric">
                                        <div class="metric-label">Retorno Esperado</div>
                                        <div class="metric-value">{ret_otimo*100:.2f}%</div>
                                    </div>
                                    <div class="metric">
                                        <div class="metric-label">Volatilidade</div>
                                        <div class="metric-value">{vol_otima*100:.2f}%</div>
                                    </div>
                                    <div class="metric">
                                        <div class="metric-label">Sharpe Ratio</div>
                                        <div class="metric-value">{sharpe_otimo:.2f}</div>
                                    </div>
                                </div>
                                
                                <h3>Aloca√ß√£o Recomendada</h3>
                                <table>
                                    <tr><th>Ativo</th><th>Peso Alocado</th></tr>
                                    {''.join([f'<tr><td>{ativo}</td><td>{peso:.2f}%</td></tr>' for ativo, peso in zip(ativos, weights_opt*100)])}
                                </table>
                                
                                <h2>üìà Fronteira Eficiente</h2>
                                <div class="chart">
                                    <img src="data:image/png;base64,{img_base64}" style="max-width: 100%; height: auto;">
                                </div>
                                
                                <h2>üé≤ Premissas de Cen√°rios</h2>
                                <h3>Probabilidades dos Cen√°rios</h3>
                                <table>
                                    <tr><th>Perfil</th><th>Bear (%)</th><th>Neutro (%)</th><th>Bull (%)</th></tr>
                                    {pd.DataFrame(st.session_state.get('probabilidades_salvas', {{}})).to_html(index=False, escape=False, header=False, border=0)}
                                </table>
                                
                                <h3>Retornos Esperados por Cen√°rio</h3>
                                {df_premissas.to_html(index=False, border=1)}
                                
                                <h2>‚öôÔ∏è Par√¢metros de Mercado</h2>
                                <table>
                                    <tr><th>Par√¢metro</th><th>Valor</th></tr>
                                    <tr><td>Taxa Pr√© (Nominal)</td><td>{st.session_state.get('parametros_mercado_salvos', {{}}).get('taxa_pre', 12):.2f}%</td></tr>
                                    <tr><td>Duration Pr√©</td><td>{st.session_state.get('parametros_mercado_salvos', {{}}).get('duration_pre', 2):.2f} anos</td></tr>
                                    <tr><td>Taxa Real (NTN-B)</td><td>{st.session_state.get('parametros_mercado_salvos', {{}}).get('taxa_real', 6):.2f}%</td></tr>
                                    <tr><td>Duration IMA-B</td><td>{st.session_state.get('parametros_mercado_salvos', {{}}).get('duration_imab', 6):.2f} anos</td></tr>
                                </table>
                                
                                <h2>üîí Restri√ß√µes de Aloca√ß√£o</h2>
                                {df_constraints_edit[['Ativo', 'Min (%)', 'Max (%)']].to_html(index=False, border=1)}
                                
                                <h2>üìä Estat√≠sticas Hist√≥ricas</h2>
                                <h3>Volatilidades Anualizadas</h3>
                                <table>
                                    <tr><th>Ativo</th><th>Volatilidade</th></tr>
                                    {''.join([f'<tr><td>{ativos_esperados[i]}</td><td>{vols[i]*100:.2f}%</td></tr>' for i in range(len(ativos_esperados))])}
                                </table>
                                
                                <div class="footer">
                                    <p>Relat√≥rio gerado automaticamente pelo sistema Ghia MFO - Asset Allocation</p>
                                    <p>¬© {datetime.now().year} - Todos os direitos reservados</p>
                                </div>
                            </div>
                        </body>
                        </html>
                        """
                            
                            # Salva o arquivo localmente
                            filename = f"{timestamp}_{perfil_selecionado}_relatorio.html"
                            
                            try:
                                with open(filename, 'w', encoding='utf-8') as f:
                                    f.write(html_content)
                                st.success(f"‚úÖ Relat√≥rio salvo localmente: **{filename}**")
                            except Exception as e:
                                st.warning(f"N√£o foi poss√≠vel salvar localmente: {e}")
                            
                            # Salva em session_state para persistir ap√≥s rerun
                            st.session_state['ultimo_relatorio'] = {
                                'html': html_content,
                                'filename': filename,
                                'timestamp': timestamp
                            }
                    
                    # Bot√£o de download (sempre vis√≠vel se houver relat√≥rio gerado)
                    if 'ultimo_relatorio' in st.session_state:
                        rel = st.session_state['ultimo_relatorio']
                        st.download_button(
                            label="‚¨áÔ∏è Download do √öltimo Relat√≥rio Gerado",
                            data=rel['html'],
                            file_name=rel['filename'],
                            mime="text/html",
                            key="download_relatorio_btn",
                            use_container_width=True
                        )
                        
                else:
                    st.error("Solu√ß√£o Invi√°vel: N√£o foi poss√≠vel encontrar uma aloca√ß√£o √≥tima.")
                    st.caption("Dica: Relaxe as restri√ß√µes de Min/Max.")
                    
                    # Debug detalhado
                    with st.expander("üîç Diagn√≥stico Detalhado", expanded=True):
                        st.write(f"**Mensagem do Solver:** {opt_result.message}")
                        st.write(f"**Status:** {opt_result.status}")
                        st.write(f"**Retornos esperados dos ativos:**")
                        for i, ativo in enumerate(ativos_esperados):
                            st.write(f"  - {ativo}: {mu[i]*100:.2f}%")
                        st.write(f"**Soma dos limites m√≠nimos:** {np.sum(min_bounds)*100:.1f}%")
            
            except Exception as e:
                st.error(f"Erro no Solver: {e}")
                st.exception(e)

## Para atualizar o codigo online, digitar no console:
# cd "C:\Users\GabrielHenriqueMarti\Desktop\Asset Allocation"

# 1. Adiciona as altera√ß√µes
# git add .

# 2. Cria um commit com descri√ß√£o
# git commit -m "Descri√ß√£o da altera√ß√£o feita"

# 3. Envia para o GitHub
# git push
